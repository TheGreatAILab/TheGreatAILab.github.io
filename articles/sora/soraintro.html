<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c4{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c7{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c10{color:#000000;text-decoration:none;vertical-align:baseline;font-family:"Arial";font-style:normal}.c3{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c8{width:33%;height:1px}.c5{font-size:10pt}.c11{font-weight:400}.c9{font-weight:700}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c3 doc-content"><p class="c6"><span class="c7">Introducing Sora</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c4">Background</span></p><p class="c1"><span class="c2">Many investors and governments are taking significant interest in Sora. This attention stems not only from its capabilities as a video generator but also from its ability to simulate worlds. This dual functionality highlights the storytelling prowess of the developers and OpenAI, which consistently presents a broad, engaging vision.</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">Sora offers several notable advantages over previous technologies. First, while earlier solutions were limited to generating a narrow range of visual data, Sora can produce more diverse and expansive open-world data. Second, previous technologies were restricted to creating short videos of fixed size and resolution, such as four-second clips at 256x256 pixels. In contrast, Sora is capable of generating videos and images in a variety of durations, aspect ratios, and resolutions, including up to a full minute of high-definition video.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c9">Method</span></p><p class="c1"><span class="c2">From my perspective, Sora incorporates two essential techniques that are crucial for its functionality. Anyone looking to reimplement Sora should give serious consideration to these techniques. Furthermore, in my view, developing new technologies that surpass Sora would require designing innovative alternatives to these two foundational techniques.</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span>The first technique employed in Sora is called Two-Stage Generation, which, despite my personal aversion to it, plays a critical role in modern image and video generators. This method involves two generators within the generation pipeline. The initial generator uses a Variational Autoencoder (VAE), such as VQGAN or VQVAE, which comprises an Encoder and a Decoder. However, during the generation process, only the Decoder is utilized. Random noise can be sampled as latent data and decoded into an image or video, facilitating the generation process. The second generator typically involves a diffusion model or a language model </span><sup><a href="#ftnt1" id="ftnt_ref1">[1]</a></sup><span class="c2">&nbsp;that generates the latent data. Notably, even without these models, the VAE alone can produce satisfactory results.</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">However, this heavy reliance on the VAE presents a significant limitation in contemporary generative models, and alternatives to this approach are relatively underexplored in the literature. The necessity of using VQGAN to train the VAE poses additional challenges, especially given the complexities associated with training GANs or VAEs. This difficulty is compounded in video generation, where a 3D VAE is required.</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">I have proposed a new method that eliminates the need to train a VAE, potentially simplifying the generation process and reducing the barriers to reproducing technologies like Sora.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">The second technique utilized in Sora is known as the Diffusion Transformer, or DiT. Traditionally, diffusion models have predominantly employed a UNet architecture. However, recent research has demonstrated benefits in replacing the UNet with a transformer architecture. This change is advantageous because it leverages what is termed the &quot;scaling law&quot;&mdash;the concept that increasing both the network size and the training data volume can significantly enhance the model&#39;s performance.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 141.50px; height: 141.50px;"><img alt="" src="images/image19.gif" style="width: 141.50px; height: 141.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 140.66px; height: 140.66px;"><img alt="" src="images/image23.gif" style="width: 140.66px; height: 140.66px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">left; base model; right: 32x of base model.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span>It is important to note that transformers have long been used instead of UNets in language models </span><sup><a href="#ftnt2" id="ftnt_ref2">[2]</a></sup><span class="c2">&nbsp;for both image and video generation. This established practice makes the transition from UNet to transformer in diffusion models a logical and intuitive step.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c4">Attractive Features</span></p><p class="c1"><span class="c2">Sora possesses several promising features that set it apart from previous technologies. </span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">Notably, Sora can generate videos with variable durations, resolutions, and aspect ratios using just a single model. This flexibility is a significant advancement over earlier methods, which often required multiple models to achieve similar results. Additionally, Sora enhances video composition by providing complete objects within the frame. This addresses a common issue in prior technologies, where videos sometimes featured only partial objects</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 95.36px; height: 170.17px;"><img alt="" src="images/image10.gif" style="width: 95.36px; height: 170.17px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 304.04px; height: 170.83px;"><img alt="" src="images/image1.gif" style="width: 304.04px; height: 170.83px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">Results of different aspect ratios</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 124.50px; height: 124.50px;"><img alt="" src="images/image16.gif" style="width: 124.50px; height: 124.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 124.50px; height: 124.50px;"><img alt="" src="images/image6.gif" style="width: 124.50px; height: 124.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">left: prior arts; right: Sora.</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">Sora demonstrates a strong capability to accurately interpret prompts, a critical aspect of image and video generation where misalignment between the prompt and the generated content often poses a significant challenge. Sora effectively addresses this issue, ensuring better alignment between prompts and outputs. The Diffusion Transformer (DiT) architecture contributes to this success by enhancing the model&#39;s understanding and response to input prompts. Additionally, the quality of annotations is significantly improved with the integration of ChatGPT enhancements, which refine short texts into more detailed and descriptive inputs, further aiding in achieving precise prompt-to-video alignment.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 331.50px; height: 186.25px;"><img alt="" src="images/image15.gif" style="width: 331.50px; height: 186.25px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">prompt: &ldquo;an old man wearing blue jeans and a white t-shirt taking a pleasant stroll in Johannesburg, South Africa during a winter storm&rdquo;</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">The tasks mentioned are related to text-to-video generation, where the video creation process is triggered by a textual prompt. Beyond text, Sora is also equipped to use images and videos as prompts to generate new videos. For instance, Sora can animate a still image. When provided with a video, Sora is capable of performing a backward extension, aligning three different videos to converge seamlessly into a specified ending video. Additionally, it can execute a forward extension to transform a video into an infinite loop. Sora also offers video-to-video editing capabilities. When given two videos, it can generate a connecting clip between them, effectively linking the two into a continuous sequence.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 156.87px; height: 159.50px;"><img alt="" src="images/image9.png" style="width: 156.87px; height: 159.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 161.50px; height: 161.50px;"><img alt="" src="images/image17.gif" style="width: 161.50px; height: 161.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">left: image; right: video</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 188.99px; height: 106.50px;"><img alt="" src="images/image14.gif" style="width: 188.99px; height: 106.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 189.50px; height: 106.75px;"><img alt="" src="images/image2.gif" style="width: 189.50px; height: 106.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 189.50px; height: 106.75px;"><img alt="" src="images/image11.gif" style="width: 189.50px; height: 106.75px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">These three video converges to the same ending video</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 240.83px; height: 135.47px;"><img alt="" src="images/image7.gif" style="width: 240.83px; height: 135.47px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">This is a video of an infinite loop (its ending point is its start point).</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 259.18px; height: 146.01px;"><img alt="" src="images/image4.gif" style="width: 259.18px; height: 146.01px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 258.93px; height: 145.86px;"><img alt="" src="images/image3.gif" style="width: 258.93px; height: 145.86px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">left: source video; right: edit it into a scene of lush jungle.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 185.70px; height: 104.61px;"><img alt="" src="images/image20.gif" style="width: 185.70px; height: 104.61px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 188.50px; height: 106.19px;"><img alt="" src="images/image12.gif" style="width: 188.50px; height: 106.19px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 185.50px; height: 104.56px;"><img alt="" src="images/image13.gif" style="width: 185.50px; height: 104.56px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">left: start scene; mid: connected scene; right: ending scene</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">Sora is also capable of generating images, as it can produce a video consisting of a single frame. This feature allows for the creation of still images using the same technology developed for video generation.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 529.50px; height: 301.69px;"><img alt="" src="images/image5.png" style="width: 529.50px; height: 301.69px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span class="c2">Sora is recognized for its impressive capability to simulate the world, which is arguably its most attractive feature. This is particularly evident in the 3D consistency of the videos it generates. For instance, Sora can create a detailed cityscape that is consistent enough in three dimensions to allow for the reconstruction of the city. Additionally, the videos maintain identity consistency; this means that objects and characters preserve their unique identities and features throughout the video, even if they are temporarily obscured or appear in widely separated segments. This feature is crucial for tasks such as object or person re-identification. Moreover, Sora enables dynamic interactions within the world. For example, if a character in a video eats a hamburger, the hamburger will show a bite mark, reflecting the interaction realistically. Lastly, Sora excels in simulating digital environments, akin to rendering dynamic physical scenes in video games with high fidelity, enhancing the realism and immersion of virtual experiences.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 249.50px; height: 140.28px;"><img alt="" src="images/image18.gif" style="width: 249.50px; height: 140.28px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 249.50px; height: 140.16px;"><img alt="" src="images/image21.gif" style="width: 249.50px; height: 140.16px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">3D consistency &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Long-range identity and feature preservation.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 251.50px; height: 140.88px;"><img alt="" src="images/image8.gif" style="width: 251.50px; height: 140.88px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 252.50px; height: 141.94px;"><img alt="" src="images/image22.gif" style="width: 252.50px; height: 141.94px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">dynamic interactions within the world &nbsp; &nbsp; &nbsp;Simulating digital world</span></p><p class="c1"><span class="c4">Limitations</span></p><p class="c1"><span class="c2">Sora has some notable limitations, particularly in accurately simulating basic physical interactions. For instance, when depicting a scenario where a glass filled with liquid drops onto a table, Sora struggles to generate results that adhere to the correct physical laws. This misalignment with real-world physics can affect the credibility of the generated scenes.</span></p><p class="c0"><span class="c2"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 366.50px; height: 206.16px;"><img alt="" src="images/image24.gif" style="width: 366.50px; height: 206.16px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c2">misalignment with real-world physics</span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><p class="c0"><span class="c2"></span></p><hr class="c8"><div><p class="c12"><a href="#ftnt_ref1" id="ftnt1">[1]</a><span class="c5">&nbsp;</span><span class="c5 c9 c10">It&rsquo;s important to clarify that in this context, a &quot;language model&quot; does not process natural language but is a directed sequential model in machine learning, used for generating images or videos. </span></p></div><div><p class="c12"><a href="#ftnt_ref2" id="ftnt2">[2]</a><span class="c5">&nbsp;</span><span class="c5 c9">It&rsquo;s important to clarify that in this context, a &quot;language model&quot; does not process natural language but is a directed sequential model in machine learning, used for generating images or videos.</span><span class="c10 c5 c11">&nbsp;</span></p></div></body></html>